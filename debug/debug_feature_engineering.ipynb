{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from audio_processing import AudioProcessor\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "INPUT_FILE = '../data/cleaned/70_15_15_cleaned_train.parquet'\n",
    "INPUT_AUDIO_DIR = '../data/raw/audio/xeno_canto'\n",
    "OUTPUT_SPECTROGRAM_DIR = '../data/processed/spectrograms/xeno_canto'\n",
    "OUTPUT_FEATURE_DIR = '../data/processed/features/xeno_canto'\n",
    "TARGET_RECORDINGS = 100\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_SPECTROGRAM_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_FEATURE_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_parquet(INPUT_FILE)\n",
    "species_counts = df['en'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/57880 [00:06<19:42:22,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "OUTPUT_AUDIO_DIR = '../data/TEST'\n",
    "os.makedirs(OUTPUT_AUDIO_DIR, exist_ok=True)\n",
    "ap = AudioProcessor(sample_rate=16000, segment_duration=20, target_db_level=-20, seed=42)\n",
    "\n",
    "for _, row in tqdm(df.head().iterrows(), total=len(df)):\n",
    "    audio_id = row['id']\n",
    "    species_name = row['en']\n",
    "    audio_files = glob.glob(os.path.join(INPUT_AUDIO_DIR, f\"{audio_id}.*\"))\n",
    "    audio_path = audio_files[0]\n",
    "\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    original_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_original.mp3\")\n",
    "    sf.write(original_save_path, y, sr, format='mp3')\n",
    "\n",
    "    if sr != 16000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        resampled_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_resampled.mp3\")\n",
    "        sf.write(resampled_save_path, y, 16000, format='mp3')\n",
    "    \n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "    trimsilence_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_trimsilence.mp3\")\n",
    "    sf.write(trimsilence_save_path, y_trimmed, 16000, format='mp3')\n",
    "    \n",
    "    y_spectral_gating = ap.spectral_gating(y_trimmed, 2.2)\n",
    "    spectral_gating_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_spectral_gating.mp3\")\n",
    "    sf.write(spectral_gating_save_path, y_spectral_gating, 16000, format='mp3')\n",
    "\n",
    "    y_normalized = ap.normalize_audio(y_spectral_gating)\n",
    "    spectral_gating_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_normalized.mp3\")\n",
    "    sf.write(spectral_gating_save_path, y_normalized, 16000, format='mp3')\n",
    "\n",
    "    target_length = 20 * 16000\n",
    "    if len(y) > target_length:\n",
    "        # Trim the audio\n",
    "        trimm_length_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_trimm_length.mp3\")\n",
    "        sf.write(trimm_length_save_path, y_normalized[:target_length], 16000, format='mp3')\n",
    "        y = y_normalized[:target_length]\n",
    "    elif len(y) < target_length:\n",
    "        # Repeat the audio to reach the target length\n",
    "        num_repeats = target_length // len(y)\n",
    "        remainder = target_length % len(y)\n",
    "        padd_length_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_padd_length.mp3\")\n",
    "        sf.write(padd_length_save_path, np.concatenate([y_normalized] * num_repeats + [y_normalized[:remainder]]), 16000, format='mp3')\n",
    "        y = np.concatenate([y_normalized] * num_repeats + [y_normalized[:remainder]])\n",
    "    else:\n",
    "        same_length_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_same_length.mp3\")\n",
    "        sf.write(same_length_save_path, y_normalized, 16000, format='mp3')\n",
    "        y = y_normalized\n",
    "        \n",
    "\n",
    "    logmel_save_path = os.path.join(OUTPUT_AUDIO_DIR, f\"{audio_id}_logmel_length.mp3\")\n",
    "    n_fft = int(0.025 * sr)  \n",
    "    hop_length = int(0.01 * sr)  \n",
    "    n_mels = 80\n",
    "    S_db = ap.create_log_mel_spectrogram(y, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    S_reconstructed = librosa.db_to_power(S_db, ref=1.0)\n",
    "    y_reconstructed = librosa.feature.inverse.mel_to_audio(\n",
    "        S_reconstructed,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        power=1.0,\n",
    "        n_iter=32,  \n",
    "    )\n",
    "    sf.write(logmel_save_path, y_reconstructed, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
