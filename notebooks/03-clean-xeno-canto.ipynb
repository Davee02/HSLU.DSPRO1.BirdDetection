{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: folium in /opt/conda/lib/python3.11/site-packages (0.18.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: branca>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from folium) (0.8.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.11/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /opt/conda/lib/python3.11/site-packages (from folium) (2024.9.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->folium) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->folium) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->folium) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->folium) (2024.8.30)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# only execute this when running on GPU Hub\n",
    "%pip install pandas folium matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import os.path\n",
    "\n",
    "from folium.plugins import MarkerCluster\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"../data/raw/xeno-canto.parquet\"\n",
    "df = pd.read_parquet(file_location)\n",
    "df_count_begin = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop entries with an unknows species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with unknown species: 3853\n"
     ]
    }
   ],
   "source": [
    "# count recordings with an unknown species\n",
    "unknown_species = df[df[\"en\"] == \"Identity unknown\"]\n",
    "print(f\"Number of rows with unknown species: {len(unknown_species)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove recordings with unknown species\n",
    "df = df[df[\"en\"] != \"Identity unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop recordings with missing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing coordinates: 980\n"
     ]
    }
   ],
   "source": [
    "# check number of recordings with missing coordinates\n",
    "missing_coordinates = df[df[\"lat\"].isna() | df[\"lng\"].isna() | df[\"lat\"].isnull() | (df['lat'].str.len() == 0) | (df['lng'].str.len() == 0)]\n",
    "print(f\"Number of rows with missing coordinates: {len(missing_coordinates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"lat\"].isna() & ~df[\"lng\"].isna() & (df['lat'].str.len() > 0) & (df['lng'].str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lng\"] = df[\"lng\"].astype(float)\n",
    "df[\"lat\"] = df[\"lat\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop species from exotic locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(df):\n",
    "    df_map = df.dropna(subset=[\"lat\", \"lng\"])\n",
    "\n",
    "    m = folium.Map()\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "    for _, row in df_map.iterrows():\n",
    "        folium.Marker(location=[row[\"lat\"], row[\"lng\"]]).add_to(marker_cluster)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all recordings on a world map\n",
    "map = plot_map(df)\n",
    "map.save(\"map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values that are too east: 211\n",
      "Values that are too west: 1\n",
      "Values that are too south: 6\n",
      "Values that are too north: 59\n"
     ]
    }
   ],
   "source": [
    "# check number of recordings with coordinates outside of mainland europe\n",
    "values_too_east = df[df[\"lng\"] > 51.83]\n",
    "values_too_west = df[df[\"lng\"] < -60]\n",
    "values_too_south = df[df[\"lat\"] < 0]\n",
    "values_too_north = df[df[\"lat\"] > 70.9]\n",
    "\n",
    "print(f\"Values that are too east: {len(values_too_east)}\")\n",
    "print(f\"Values that are too west: {len(values_too_west)}\")\n",
    "print(f\"Values that are too south: {len(values_too_south)}\")\n",
    "print(f\"Values that are too north: {len(values_too_north)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those recordings\n",
    "df = df.drop(values_too_east.index).drop(values_too_west.index).drop(values_too_south.index).drop(values_too_north.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the map again\n",
    "map = plot_map(df)\n",
    "map.save(\"map_filtered.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop species with less than 25 recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_per_species = df[\"en\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species with more than 25 recordings: 275\n"
     ]
    }
   ],
   "source": [
    "# drop species with less than 25 recordings\n",
    "species_with_few_recordings = recordings_per_species[recordings_per_species < 25].index\n",
    "print(f\"Species with more than 25 recordings: {len(species_with_few_recordings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"en\"].isin(species_with_few_recordings)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop recordings without an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of recordings with missing file urls\n",
    "(df[\"file\"].str.len() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check again but against null values\n",
    "df[\"file\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82691/82691 [00:04<00:00, 17639.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing audio files: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['357351', '441473', '516953', '246962', '825922']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through all recordings and check if the audio file exists\n",
    "\n",
    "def check_audio_file_exists(file_name) -> bool:\n",
    "    return os.path.exists(f\"../data/raw/audio/xeno_canto/{file_name}\")\n",
    "\n",
    "missing_audio_files = []\n",
    "for _, recording_data in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    audio_url = recording_data[\"file\"]\n",
    "    original_audio_file_name = recording_data[\"file-name\"]\n",
    "    file_extension = original_audio_file_name.split(\".\")[-1]\n",
    "    new_audio_file_name = f\"{recording_data['id']}.{file_extension}\"\n",
    "\n",
    "    if not check_audio_file_exists(new_audio_file_name):\n",
    "        missing_audio_files.append(recording_data[\"id\"])\n",
    "\n",
    "print(f\"Number of missing audio files: {len(missing_audio_files)}\")\n",
    "missing_audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop recordings with missing audio files\n",
    "df = df[~df[\"id\"].isin(missing_audio_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recordings remaining: 82686\n",
      "Number of recordings removed: 6860\n",
      "Percentage of recordings removed: 7.66%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of recordings remaining: {len(df)}\")\n",
    "print(f\"Number of recordings removed: {df_count_begin - len(df)}\")\n",
    "print(f\"Percentage of recordings removed: {(df_count_begin - len(df)) / df_count_begin * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the columns we need\n",
    "df = df[[\"id\", \"en\", \"lat\", \"lng\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data/cleaned/cleaned_data.parquet', engine='pyarrow', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
