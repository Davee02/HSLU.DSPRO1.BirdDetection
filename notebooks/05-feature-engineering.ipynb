{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3057368-4099-42dd-9579-270647aa3a61",
   "metadata": {},
   "source": [
    "# Resampling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6a6340-051f-4385-9068-8282a45dddc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ee4c09-e5c5-4149-b9b3-09fab876a687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maiko\\AppData\\Local\\Temp\\ipykernel_13256\\3583556299.py:33: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_path, sr=None)\n",
      "C:\\Users\\maiko\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 375211: \n",
      "No audio file found for ID 899960. Skipping.\n",
      "No audio file found for ID 930482. Skipping.\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_csv = '../data/cleaned/70_15_15_cleaned_train.csv'\n",
    "input_audio_dir = '../data/raw/audio/xeno_canto'\n",
    "output_audio_dir = '../data/processed/audio/xeno_canto'\n",
    "\n",
    "\n",
    "os.makedirs(output_audio_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "sample_rate = 16000  # Set sample rate the same as used in the pretrained model\n",
    "target_db_level = -20  \n",
    "\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    audio_id = row['id']\n",
    "    \n",
    "\n",
    "    audio_path_pattern = os.path.join(input_audio_dir, f\"{audio_id}.*\")\n",
    "    audio_files = glob.glob(audio_path_pattern)\n",
    "    \n",
    "    if len(audio_files) == 0:\n",
    "        print(f\"No audio file found for ID {audio_id}. Skipping.\")\n",
    "        continue\n",
    "    elif len(audio_files) > 1:\n",
    "        print(f\"Multiple audio files found for ID {audio_id}. Skipping to avoid ambiguity.\")\n",
    "        continue\n",
    "    \n",
    "    audio_path = audio_files[0]\n",
    "    \n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        if sr != sample_rate:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=sample_rate)\n",
    "            sr = sample_rate\n",
    "        \n",
    "        rms = librosa.feature.rms(y=y)[0]\n",
    "        current_db = librosa.amplitude_to_db(rms, ref=np.max)\n",
    "        db_adjustment = target_db_level - np.mean(current_db)\n",
    "        y = y * (10 ** (db_adjustment / 20))\n",
    "\n",
    "        output_path = os.path.join(output_audio_dir, f\"{audio_id}.wav\")\n",
    "        sf.write(output_path, y, sr)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_id}: {e}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb362d3-b111-4e32-8eb3-662369b9cf64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trim and Segment Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3050ff-dcb6-4aac-ab44-b4dbfcffb972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maiko\\AppData\\Local\\Temp\\ipykernel_13256\\3014704189.py:19: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_path, sr=sample_rate)\n",
      "C:\\Users\\maiko\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 375211: [Errno 2] No such file or directory: '../data/processed/audio/xeno_canto\\\\375211.wav'\n",
      "Error processing 899960: [Errno 2] No such file or directory: '../data/processed/audio/xeno_canto\\\\899960.wav'\n",
      "Error processing 930482: [Errno 2] No such file or directory: '../data/processed/audio/xeno_canto\\\\930482.wav'\n",
      "Audio trimming and segmentation complete with overlapping segments.\n"
     ]
    }
   ],
   "source": [
    "input_audio_dir = '../data/processed/audio/xeno_canto'  # Assuming previous output directory as input here\n",
    "output_audio_dir = '../data/processed/segmented_audio/xeno_canto'\n",
    "\n",
    "os.makedirs(output_audio_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "sample_rate = 16000  \n",
    "segment_duration = 5  # Segment duration in seconds\n",
    "overlap_duration = 1  # Overlap duration in seconds\n",
    "target_db_level = -20  \n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    audio_id = row['id']\n",
    "    audio_path = os.path.join(input_audio_dir, f\"{audio_id}.wav\")\n",
    "    \n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "        \n",
    "        # Trim silence from the beginning and end of the audio\n",
    "        y, _ = librosa.effects.trim(y, top_db=20) \n",
    "\n",
    "        # Normalize the audio to target dB level\n",
    "        rms = librosa.feature.rms(y=y)[0]\n",
    "        current_db = librosa.amplitude_to_db(rms, ref=np.max)\n",
    "        db_adjustment = target_db_level - np.mean(current_db)\n",
    "        y = y * (10 ** (db_adjustment / 20))\n",
    "\n",
    "        # Calculate segment and overlap lengths in samples\n",
    "        segment_length = segment_duration * sr\n",
    "        overlap_length = overlap_duration * sr\n",
    "        step = segment_length - overlap_length  \n",
    "\n",
    "        # Split audio into overlapping segments\n",
    "        total_segments = int(np.ceil((len(y) - overlap_length) / step))\n",
    "\n",
    "        for i in range(total_segments):\n",
    "            start = i * step\n",
    "            end = min(start + segment_length, len(y))\n",
    "            segment = y[start:end]\n",
    "\n",
    "            if len(segment) < segment_length and end != len(y):\n",
    "                continue\n",
    "            \n",
    "            segment_filename = f\"{audio_id}_segment_{i+1}.wav\"\n",
    "            output_path = os.path.join(output_audio_dir, segment_filename)\n",
    "            sf.write(output_path, segment, sr)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_id}: {e}\")\n",
    "\n",
    "print(\"Audio trimming and segmentation complete with overlapping segments.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b10ce5-4891-4785-9064-62affb53c78d",
   "metadata": {},
   "source": [
    "# Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ad7947-e360-46e0-8d6e-0e447b27e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel-spectrogram generation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input_audio_dir = '../data/processed/segmented_audio/xeno_canto'\n",
    "output_spectrogram_dir = '../data/processed/spectrograms/xeno_canto'\n",
    "os.makedirs(output_spectrogram_dir, exist_ok=True)\n",
    "\n",
    "sample_rate = 16000  \n",
    "audio_files = [f for f in os.listdir(input_audio_dir) if f.endswith('.wav')]\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(input_audio_dir, audio_file)\n",
    "    audio_id, segment_num = audio_file.split('_segment_')\n",
    "    segment_num = segment_num.split('.')[0]\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Plot the mel-spectrogram without extra text or labels\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(S_db, sr=sr, hop_length=512, x_axis=None, y_axis=None)\n",
    "        plt.axis('off')  \n",
    "        spectrogram_filename = f\"{audio_id}_segment_{segment_num}.png\"\n",
    "        spectrogram_path = os.path.join(output_spectrogram_dir, spectrogram_filename)\n",
    "        plt.savefig(spectrogram_path, bbox_inches='tight', pad_inches=0) \n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_file}: {e}\")\n",
    "\n",
    "print(\"Mel-spectrogram generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfea54-7d63-47d6-8eb8-17302d621ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
