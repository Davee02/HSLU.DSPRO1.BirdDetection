{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.2.post1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nevin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nevin\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/390.3 MB 16.8 MB/s eta 0:00:23\n",
      "    --------------------------------------- 7.1/390.3 MB 17.5 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 11.8/390.3 MB 18.9 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 17.8/390.3 MB 21.2 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 23.3/390.3 MB 22.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 28.8/390.3 MB 23.4 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 34.3/390.3 MB 24.0 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 39.3/390.3 MB 24.3 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 45.4/390.3 MB 24.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 50.9/390.3 MB 24.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 56.6/390.3 MB 25.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 62.1/390.3 MB 25.4 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 67.6/390.3 MB 25.5 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 73.7/390.3 MB 25.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 79.2/390.3 MB 25.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 84.7/390.3 MB 25.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 90.2/390.3 MB 26.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 95.7/390.3 MB 26.1 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 101.7/390.3 MB 26.2 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 107.5/390.3 MB 26.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 113.0/390.3 MB 26.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 118.5/390.3 MB 26.3 MB/s eta 0:00:11\n",
      "   ------------ -------------------------- 124.0/390.3 MB 26.4 MB/s eta 0:00:11\n",
      "   ------------ -------------------------- 129.5/390.3 MB 26.4 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 135.0/390.3 MB 26.5 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 140.5/390.3 MB 26.5 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 146.3/390.3 MB 26.5 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 151.8/390.3 MB 26.6 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 157.5/390.3 MB 26.6 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 163.6/390.3 MB 26.6 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 169.1/390.3 MB 26.6 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 174.9/390.3 MB 26.7 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 180.9/390.3 MB 26.7 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 186.4/390.3 MB 26.7 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 191.9/390.3 MB 26.7 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 197.7/390.3 MB 26.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 203.2/390.3 MB 26.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 208.9/390.3 MB 26.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 214.4/390.3 MB 26.8 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 220.2/390.3 MB 26.8 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 225.7/390.3 MB 26.8 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 231.5/390.3 MB 26.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 237.0/390.3 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 242.7/390.3 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 248.5/390.3 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 254.5/390.3 MB 26.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 260.0/390.3 MB 26.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 265.6/390.3 MB 27.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 271.1/390.3 MB 27.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 276.6/390.3 MB 27.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 282.1/390.3 MB 27.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 287.8/390.3 MB 27.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 293.9/390.3 MB 27.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 299.4/390.3 MB 27.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 304.9/390.3 MB 27.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 310.4/390.3 MB 27.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 315.9/390.3 MB 27.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 321.4/390.3 MB 27.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.5/390.3 MB 27.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 329.8/390.3 MB 27.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 335.0/390.3 MB 27.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 340.8/390.3 MB 27.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 346.3/390.3 MB 27.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 352.1/390.3 MB 27.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 357.8/390.3 MB 27.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.3/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 368.8/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.9/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.4/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.1/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 27.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 26.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 26.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 29.1 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 5.8/26.4 MB 27.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.4 MB 27.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 27.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa\n",
    "%pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../../data/cleaned/70_15_15_cleaned_train.csv\"\n",
    "val_file = \"../../data/cleaned/70_15_15_cleaned_val.csv\"\n",
    "audio_folder = \"../../data/raw/audio/xeno-canto/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_mfcc = 40  # Number of MFCC features\n",
    "max_pad_len = 173  # Maximum padding length for audio\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess audio files\n",
    "def preprocess_audio(file_id, folder, max_pad_len=173, n_mfcc=40):\n",
    "    file_path_mp3 = os.path.join(folder, f\"{file_id}.mp3\")\n",
    "    file_path_wav = os.path.join(folder, f\"{file_id}.wav\")\n",
    "    file_path = file_path_mp3 if os.path.exists(file_path_mp3) else file_path_wav\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        if pad_width > 0:\n",
    "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfcc = mfcc[:, :max_pad_len]\n",
    "        return mfcc\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset\n",
    "def load_dataset(csv_file, audio_folder, n_mfcc=40, max_pad_len=173):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    audio_features = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        mfcc = preprocess_audio(row['id'], audio_folder, max_pad_len, n_mfcc)\n",
    "        if mfcc is not None:\n",
    "            audio_features.append(mfcc)\n",
    "            labels.append(row['en'])  # Assuming 'en' is the target label\n",
    "    return np.array(audio_features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset sample:\n",
      "   Unnamed: 0.1  Unnamed: 0      id         gen          sp  ssp  group  \\\n",
      "0         12324       14055  370848     Egretta    garzetta  NaN  birds   \n",
      "1         10347       11625  629154       Larus  argentatus  NaN  birds   \n",
      "2         15365       17353  579339       Picus     viridis  NaN  birds   \n",
      "3         23668       26557  802334     Sturnus    vulgaris  NaN  birds   \n",
      "4         11397       13042  799697  Ixobrychus     minutus  NaN  birds   \n",
      "\n",
      "                          en               rec                 cnt  ...  \\\n",
      "0               Little Egret  Albert Lastukhin  Russian Federation  ...   \n",
      "1      European Herring Gull     Meena Haribal              Norway  ...   \n",
      "2  European Green Woodpecker       Samuel Levy      United Kingdom  ...   \n",
      "3            Common Starling  Susanne Kuijpers         Netherlands  ...   \n",
      "4             Little Bittern     Ricardo Hevia               Spain  ...   \n",
      "\n",
      "                                                 rmk  bird-seen  animal-seen  \\\n",
      "0                                                NaN    unknown      unknown   \n",
      "1                                                NaN        yes          yes   \n",
      "2  Unmodified recording using Tascam DR-05x \\r\\nO...         no           no   \n",
      "3                                                NaN         no           no   \n",
      "4                                                NaN         no           no   \n",
      "\n",
      "  playback-used temperature regnr auto  dvc  mic    smp  \n",
      "0            no         NaN   NaN   no  NaN  NaN  44100  \n",
      "1            no         NaN   NaN   no  NaN  NaN  44100  \n",
      "2            no         NaN   NaN   no  NaN  NaN  44100  \n",
      "3            no         NaN   NaN  yes  NaN  NaN  44100  \n",
      "4            no         NaN   NaN  yes  NaN  NaN  44100  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "\n",
      "Validation dataset sample:\n",
      "   Unnamed: 0.1  Unnamed: 0      id       gen         sp  ssp  group  \\\n",
      "0         27521       30969  838304  Prunella  modularis  NaN  birds   \n",
      "1         12892       14744  708453      Tyto       alba  NaN  birds   \n",
      "2          2063        2523  423557      Apus   pallidus  NaN  birds   \n",
      "3         28608       32182  714883    Anthus  pratensis  NaN  birds   \n",
      "4         25763       28804  716072    Turdus  torquatus  NaN  birds   \n",
      "\n",
      "                 en               rec       cnt  ...  \\\n",
      "0           Dunnock        Théo Hervé    France  ...   \n",
      "1  Western Barn Owl  Nelson Conceição  Portugal  ...   \n",
      "2      Pallid Swift         Carlos W.     Spain  ...   \n",
      "3      Meadow Pipit    Manceau Lionel    France  ...   \n",
      "4        Ring Ouzel     Lars Mogensen   Denmark  ...   \n",
      "\n",
      "                                                 rmk  bird-seen  animal-seen  \\\n",
      "0                                                NaN         no           no   \n",
      "1  Recorder: Zoom H1n\\r\\n\\r\\nWindscreen: Zoom WSU...         no           no   \n",
      "2                    Birds calling from their nests.        yes          yes   \n",
      "3                                                NaN        yes          yes   \n",
      "4                                                NaN    unknown      unknown   \n",
      "\n",
      "  playback-used temperature regnr auto  dvc  mic    smp  \n",
      "0            no         NaN   NaN  yes  NaN  NaN  44100  \n",
      "1            no         NaN   NaN   no  NaN  NaN  48000  \n",
      "2            no         NaN   NaN   no  NaN  NaN  44100  \n",
      "3            no         NaN   NaN   no  NaN  NaN  48000  \n",
      "4       unknown         NaN   NaN   no  NaN  NaN  44100  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"../../data/cleaned/70_15_15_cleaned_train.csv\")\n",
    "val_df = pd.read_csv(\"../../data/cleaned/70_15_15_cleaned_val.csv\")\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Training dataset sample:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation dataset sample:\")\n",
    "print(val_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing audio files for 22754 IDs.\n",
      "Example missing file IDs: [370848, 629154, 579339, 802334, 799697, 723673, 842246, 384576, 892221, 411273]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "audio_folder = \"../data/raw/audio/xeno-canto/\"\n",
    "missing_files = []\n",
    "\n",
    "# Check if files exist\n",
    "for file_id in train_df['id']:\n",
    "    mp3_path = os.path.join(audio_folder, f\"{file_id}.mp3\")\n",
    "    wav_path = os.path.join(audio_folder, f\"{file_id}.wav\")\n",
    "    if not (os.path.exists(mp3_path) or os.path.exists(wav_path)):\n",
    "        missing_files.append(file_id)\n",
    "\n",
    "print(f\"Missing audio files for {len(missing_files)} IDs.\")\n",
    "if len(missing_files) > 0:\n",
    "    print(\"Example missing file IDs:\", missing_files[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing training data...\n",
      "Loading and preprocessing validation data...\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training and validation datasets\n",
    "print(\"Loading and preprocessing training data...\")\n",
    "X_train, y_train = load_dataset(train_file, audio_folder, n_mfcc, max_pad_len)\n",
    "print(\"Loading and preprocessing validation data...\")\n",
    "X_val, y_val = load_dataset(val_file, audio_folder, n_mfcc, max_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (0,)\n",
      "y_train sample: []\n",
      "y_val shape: (0,)\n",
      "y_val sample: []\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train sample:\", y_train[:10])  # Print the first 10 labels\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_val sample:\", y_val[:10])  # Print the first 10 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m X_val[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m      5\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 6\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y_val \u001b[38;5;241m=\u001b[39m to_categorical(le\u001b[38;5;241m.\u001b[39mtransform(y_val))\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:96\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     94\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m num_classes:\n\u001b[1;32m---> 96\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2899\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2781\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2784\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2897\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2898\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2900\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Reshape for CNN input and encode labels\n",
    "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "X_val = X_val[..., np.newaxis]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(le.fit_transform(y_train))\n",
    "y_val = to_categorical(le.transform(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(n_mfcc, max_pad_len, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"Training the CNN model...\")\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn_audio_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
