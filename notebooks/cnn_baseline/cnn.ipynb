{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "spectrogram_folder = os.path.abspath(\"../../data/processed/spectrograms/xeno_canto/\")\n",
    "train_parquet_file = \"../../data/cleaned/70_15_15_cleaned_train.parquet\"\n",
    "val_parquet_file = \"../../data/cleaned/70_15_15_cleaned_val.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_spectrogram_files(spectrogram_folder):\n",
    "    \"\"\"\n",
    "    Create an index of spectrogram files for quick lookup.\n",
    "    \"\"\"\n",
    "    spectrogram_files = os.listdir(spectrogram_folder)\n",
    "    file_index = {}\n",
    "\n",
    "    for filename in spectrogram_files:\n",
    "        file_id = filename.split('_')[0]\n",
    "        if file_id not in file_index:\n",
    "            file_index[file_id] = []\n",
    "        file_index[file_id].append(os.path.join(spectrogram_folder, filename))\n",
    "    \n",
    "    return file_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectrogram(spec, target_shape):\n",
    "    \"\"\"\n",
    "    Normalize a spectrogram to the target shape by padding or truncating.\n",
    "    \"\"\"\n",
    "    if spec.shape == target_shape:\n",
    "        return spec\n",
    "    elif spec.shape[1] < target_shape[1]:  # Pad if too short\n",
    "        pad_width = target_shape[1] - spec.shape[1]\n",
    "        return np.pad(spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:  # Truncate if too long\n",
    "        return spec[:, :target_shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrograms_by_id(file_id, spectrogram_folder, target_shape=(128, 626)):\n",
    "    file_id = str(file_id).strip()\n",
    "    if file_id not in file_index:\n",
    "        return None\n",
    "\n",
    "    spectrograms = []\n",
    "    for full_path in file_index[file_id]:\n",
    "        try:\n",
    "            spec = np.load(full_path)\n",
    "            spec = normalize_spectrogram(spec, target_shape)  # Normalize the shape\n",
    "            spectrograms.append(spec)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {full_path}: {e}\")\n",
    "\n",
    "    if spectrograms:\n",
    "        return np.mean(np.array(spectrograms), axis=0)  # Combine all spectrograms\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, spectrogram_folder):\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        spec_id = row['id']\n",
    "        spectrogram = load_spectrograms_by_id(spec_id, spectrogram_folder)\n",
    "        \n",
    "        if spectrogram is not None:\n",
    "            X.append(spectrogram)\n",
    "            y.append(row['en'])  # Assuming 'en' is the target label\n",
    "        else:\n",
    "            print(f\"No spectrogram found for ID: {spec_id}\")\n",
    "    print(f\"Processed {len(X)} samples with {len(y)} labels.\")\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training and validation data...\n"
     ]
    }
   ],
   "source": [
    "# Load parquet files\n",
    "print(\"Loading training and validation data...\")\n",
    "train_df = pd.read_parquet(train_parquet_file)\n",
    "val_df = pd.read_parquet(val_parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spectrograms_in_batches(parquet_df, spectrogram_folder, target_shape=(128, 626), batch_size=50):\n",
    "    num_rows = len(parquet_df)\n",
    "    X, y = [], []\n",
    "    missing_spectrograms = []\n",
    "\n",
    "    # Process DataFrame in batches\n",
    "    for start_idx in tqdm(range(0, num_rows, batch_size), desc=\"Processing Spectrograms\"):\n",
    "        batch_df = parquet_df.iloc[start_idx:start_idx + batch_size]\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            spec_id = row['id']\n",
    "            label = row['en']  # Assuming 'en' is the label column\n",
    "            result = load_spectrograms_by_id(spec_id, file_index, target_shape)\n",
    "            if result is None:\n",
    "                missing_spectrograms.append(spec_id)\n",
    "            else:\n",
    "                X.append(result)\n",
    "                y.append(label)\n",
    "\n",
    "    print(f\"Missing spectrograms: {len(missing_spectrograms)}\")\n",
    "    if missing_spectrograms:\n",
    "        print(f\"Example missing spectrogram IDs: {missing_spectrograms[:10]}\")\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing spectrogram files...\n",
      "Processing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Spectrograms: 100%|██████████| 1158/1158 [06:17<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing spectrograms: 17\n",
      "Example missing spectrogram IDs: ['901488', '340489', '356231', '930482', '899960', '892404', '767021', '470775', '701858', '375211']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Pre-index spectrogram files\n",
    "print(\"Indexing spectrogram files...\")\n",
    "file_index = index_spectrogram_files(spectrogram_folder)\n",
    "\n",
    "# Process training data\n",
    "print(\"Processing training data...\")\n",
    "X_train, y_train = process_spectrograms_in_batches(train_df, file_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (0,)\n",
      "y_train sample: Empty\n",
      "y_val shape: (0,)\n",
      "y_val sample: Empty\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_train sample:\", y_train[:10] if len(y_train) > 0 else \"Empty\")\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_val sample:\", y_val[:10] if len(y_val) > 0 else \"Empty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding labels...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_val \u001b[38;5;241m=\u001b[39m to_categorical(le\u001b[38;5;241m.\u001b[39mtransform(y_val))\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:96\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     94\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m num_classes:\n\u001b[1;32m---> 96\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2899\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2781\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2784\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2897\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2898\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2900\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "print(\"Encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(le.fit_transform(y_train))\n",
    "y_val = to_categorical(le.transform(y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
